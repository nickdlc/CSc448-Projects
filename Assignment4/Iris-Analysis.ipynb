{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a774689",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nickdlc/CSc448-Projects/blob/main/Assignment4/Iris-Analysis.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "id": "93c1adfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa4bf89",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "id": "758a2f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                 5.1               3.5                1.4               0.2   \n",
       "1                 4.9               3.0                1.4               0.2   \n",
       "2                 4.7               3.2                1.3               0.2   \n",
       "3                 4.6               3.1                1.5               0.2   \n",
       "4                 5.0               3.6                1.4               0.2   \n",
       "5                 5.4               3.9                1.7               0.4   \n",
       "6                 4.6               3.4                1.4               0.3   \n",
       "7                 5.0               3.4                1.5               0.2   \n",
       "8                 4.4               2.9                1.4               0.2   \n",
       "9                 4.9               3.1                1.5               0.1   \n",
       "10                5.4               3.7                1.5               0.2   \n",
       "11                4.8               3.4                1.6               0.2   \n",
       "12                4.8               3.0                1.4               0.1   \n",
       "13                4.3               3.0                1.1               0.1   \n",
       "14                5.8               4.0                1.2               0.2   \n",
       "\n",
       "    target  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "5        0  \n",
       "6        0  \n",
       "7        0  \n",
       "8        0  \n",
       "9        0  \n",
       "10       0  \n",
       "11       0  \n",
       "12       0  \n",
       "13       0  \n",
       "14       0  "
      ]
     },
     "execution_count": 913,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the iris dataset and show the first 15 rows\n",
    "iris = load_iris(as_frame=True)\n",
    "df = iris['frame']\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "id": "38c2d543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)      target  \n",
       "count        150.000000  150.000000  \n",
       "mean           1.199333    1.000000  \n",
       "std            0.762238    0.819232  \n",
       "min            0.100000    0.000000  \n",
       "25%            0.300000    0.000000  \n",
       "50%            1.300000    1.000000  \n",
       "75%            1.800000    2.000000  \n",
       "max            2.500000    2.000000  "
      ]
     },
     "execution_count": 914,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show a summary of the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "id": "b88c419a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal length (cm)    0\n",
       "sepal width (cm)     0\n",
       "petal length (cm)    0\n",
       "petal width (cm)     0\n",
       "target               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 915,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "id": "55b88d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 916,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique values of 'target' column\n",
    "df['target'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82793a64",
   "metadata": {},
   "source": [
    "## About the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74d6051",
   "metadata": {},
   "source": [
    "The dataset contains 150 flowers and records four different characteristics for each flower:\n",
    "* Sepal length (cm)\n",
    "* Sepal width (cm)\n",
    "* Petal length (cm)\n",
    "* Petal width (cm)\n",
    "\n",
    "Moreover, the dataset contains a target column which has three possible values from the set {0,1,2}. These three distinct possibilities likely mean that there are three different flower species in the dataset, and these flower properties are the features used to classify each flower."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287a9ae6",
   "metadata": {},
   "source": [
    "# Split the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "id": "2b9ec1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Divide the dataset into features and label(s)\n",
    "X = df.drop(['target'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Split the data into train (90%) and test (10%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=22)\n",
    "\n",
    "# Split the data into train (67%) and test (33%) sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d537da",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e243fb0",
   "metadata": {},
   "source": [
    "## Training the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "id": "5be11882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train the model using our training data\n",
    "logreg = LogisticRegression(random_state=22, max_iter=200) # set max_iter to reach convergence and avoid warning\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the output for each flower in the test set\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828602f5",
   "metadata": {},
   "source": [
    "## Predicting Probabilities for Each Class for Sample Data Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "id": "e3593929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point X0\n",
      "Probability of class 0: 9.886265607331051e-25\n",
      "Probability of class 1: 8.855563560036231e-13\n",
      "Probability of class 2: 0.9999999999991145\n",
      "\n",
      "Point X1\n",
      "Probability of class 0: 0.9953922955320623\n",
      "Probability of class 1: 0.004607701365240459\n",
      "Probability of class 2: 3.102697239824551e-09\n",
      "\n",
      "Point X2\n",
      "Probability of class 0: 0.013854012075532204\n",
      "Probability of class 1: 0.8984185571453003\n",
      "Probability of class 2: 0.08772743077916749\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a new point and predict the probabilites for each classification\n",
    "X0 = [[15.8, 8.8, 13.8, 5], [2.15, 1, 0.5, 0.05], [5.8, 3, 4.35, 1.3]]\n",
    "X0_pred = pd.DataFrame(X0, columns=X_test.columns)\n",
    "y0_probs = logreg.predict_proba(X0_pred)\n",
    "\n",
    "for i in range(len(y0_probs)):\n",
    "    print('Point X' + str(i))\n",
    "    for j in range(len(y0_probs[i])):\n",
    "        print('Probability of class', str(j) + ':', y0_probs[i][j])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "id": "0568fdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a new point X0 the model classifies it as iris 2\n",
      "Given a new point X1 the model classifies it as iris 0\n",
      "Given a new point X2 the model classifies it as iris 1\n"
     ]
    }
   ],
   "source": [
    "# Verify that the model chooses the class with the highest probability\n",
    "y0_pred = logreg.predict(X0_pred)\n",
    "\n",
    "for i in range(len(y0_pred)):\n",
    "    print('Given a new point X' + str(i), 'the model classifies it as iris', y0_pred[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d9d420",
   "metadata": {},
   "source": [
    "## Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "id": "2999c242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's score is: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Display the model's score\n",
    "logreg_score = logreg.score(X_test, y_test)\n",
    "# logreg_score = logreg.score(X0_pred, y0_pred)\n",
    "print('The model\\'s score is:', logreg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69da9116",
   "metadata": {},
   "source": [
    "The logistic regression model has a score of 1, and this means that it can classify a flower as one of the three iris species with about 100% accuracy from the testing set or an entirely new point $X_0$.\n",
    "\n",
    "When using a training set size of 67% and a test set size of 33%, this model has a score of 0.96, meaning it can properly classify the iris species with about 96% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4ca779",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "id": "15db851b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficients are: [[-0.41663174  0.95122844 -2.44264802 -1.04324609]\n",
      " [ 0.4532748  -0.32750687 -0.1992296  -0.80915027]\n",
      " [-0.03664306 -0.62372158  2.64187762  1.85239636]]\n",
      "The intercepts are: [  9.53861062   2.43822503 -11.97683565]\n"
     ]
    }
   ],
   "source": [
    "logreg_coefs = logreg.coef_\n",
    "logreg_intercept = logreg.intercept_\n",
    "\n",
    "print('The coefficients are:', logreg_coefs)\n",
    "print('The intercepts are:', logreg_intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82d95a0",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d826cb9d",
   "metadata": {},
   "source": [
    "## Training the Support Vector Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "id": "0c16dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svclf = SVC(random_state=22, probability=True)\n",
    "svclf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992f7514",
   "metadata": {},
   "source": [
    "## Predicting Probabilities for Each Class for Sample Data Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "id": "adfb8861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point X0\n",
      "Probability of class 0: 0.3563909475965388\n",
      "Probability of class 1: 0.2414443096329036\n",
      "Probability of class 2: 0.4021647427705573\n",
      "\n",
      "Point X1\n",
      "Probability of class 0: 0.8143933713532433\n",
      "Probability of class 1: 0.09096295563272797\n",
      "Probability of class 2: 0.094643673014029\n",
      "\n",
      "Point X2\n",
      "Probability of class 0: 0.00899296022121033\n",
      "Probability of class 1: 0.9636723559621025\n",
      "Probability of class 2: 0.027334683816687192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the new point X0 and predict the probabilities for each classification\n",
    "y0_pred_svm = svclf.predict(X0_pred)\n",
    "y0_probs_svm = svclf.predict_proba(X0_pred)\n",
    "\n",
    "for i in range(len(y0_probs_svm)):\n",
    "    print('Point X' + str(i))\n",
    "    for j in range(len(y0_probs_svm[i])):\n",
    "        print('Probability of class', str(j) + ':', y0_probs_svm[i][j])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "id": "10227530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a new point X0 the model classifies it as iris 2\n",
      "Given a new point X1 the model classifies it as iris 0\n",
      "Given a new point X2 the model classifies it as iris 1\n"
     ]
    }
   ],
   "source": [
    "# Verify that the model chooses the class with the highest probability\n",
    "for i in range(len(y0_pred_svm)):\n",
    "    print('Given a new point X' + str(i), 'the model classifies it as iris', y0_pred[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c105b2e",
   "metadata": {},
   "source": [
    "## Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "id": "322b1cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's score is: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Display the model's score\n",
    "svm_score = svclf.score(X_test, y_test)\n",
    "# svm_score = svclf.score(X0_pred, y0_pred_svm)\n",
    "print('The model\\'s score is:', svm_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ded79d",
   "metadata": {},
   "source": [
    "The support vector machine model has a score of 0.93, and this means that it can classify a flower as one of the three iris species with about 93% accuracy from the testing set or an entirely new point $X_0$.\n",
    "\n",
    "When using a training set size of 67% and a test set size of 33%, this model has a score of 0.92, meaning it can properly classify the iris species with about 92% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa094a3c",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c5c1d6",
   "metadata": {},
   "source": [
    "## Training the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "id": "33d739b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlpclf = MLPClassifier(random_state=22, max_iter=600) # set max_iter to reach convergence and avoid warning\n",
    "mlpclf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_mlp = mlpclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10941de6",
   "metadata": {},
   "source": [
    "## Predicting Probabilities for Each Class for Sample Data Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "id": "f3f9d093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point X0\n",
      "Probability of class 0: 4.805637683626675e-16\n",
      "Probability of class 1: 3.674451114418523e-08\n",
      "Probability of class 2: 0.9999999632554883\n",
      "\n",
      "Point X1\n",
      "Probability of class 0: 0.9170162399708093\n",
      "Probability of class 1: 0.08298188668576408\n",
      "Probability of class 2: 1.8733434266134747e-06\n",
      "\n",
      "Point X2\n",
      "Probability of class 0: 0.0028154864224915663\n",
      "Probability of class 1: 0.9877627893021205\n",
      "Probability of class 2: 0.009421724275388016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the new point X0 and predict the probabilities for each classification\n",
    "y0_pred_mlp = mlpclf.predict(X0_pred)\n",
    "y0_probs_mlp = mlpclf.predict_proba(X0_pred)\n",
    "\n",
    "for i in range(len(y0_probs_mlp)):\n",
    "    print('Point X' + str(i))\n",
    "    for j in range(len(y0_probs_mlp[i])):\n",
    "        print('Probability of class', str(j) + ':', y0_probs_mlp[i][j])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "id": "f763d1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a new point X0 the model classifies it as iris 2\n",
      "Given a new point X1 the model classifies it as iris 0\n",
      "Given a new point X2 the model classifies it as iris 1\n"
     ]
    }
   ],
   "source": [
    "# Verify that the model chooses the class with the highest probability\n",
    "for i in range(len(y0_pred_mlp)):\n",
    "    print('Given a new point X' + str(i), 'the model classifies it as iris', y0_pred_mlp[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d50863",
   "metadata": {},
   "source": [
    "## Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "id": "738d9ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's score is: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Display the model's score\n",
    "mlp_score = mlpclf.score(X_test, y_test)\n",
    "# mlp_score = mlpclf.score(X0_pred, y0_pred_mlp)\n",
    "print('The model\\'s score is:', mlp_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755846bd",
   "metadata": {},
   "source": [
    "The neural network/MLP classifier model has a score of 1, and this means that it can classify a flower as one of the three iris species with 100% accuracy from the testing set or an entirely new point $X_0$.\n",
    "\n",
    "When using a training set size of 67% and a test set size of 33%, this model has a score of 1, meaning it can properly classify the iris species with 100% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a9e6a8",
   "metadata": {},
   "source": [
    "## Experimenting with Different Options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2475bb4f",
   "metadata": {},
   "source": [
    "### Activation Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "id": "cf632ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using activation option: IDENTITY\n",
      "The model's score is: 1.0 \n",
      "\n",
      "Using activation option: LOGISTIC\n",
      "The model's score is: 1.0 \n",
      "\n",
      "Using activation option: TANH\n",
      "The model's score is: 1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "activation_options = ['identity', 'logistic', 'tanh'] # relu is the default\n",
    "\n",
    "for option in activation_options:\n",
    "    print('Using activation option: ' + option.upper())\n",
    "    mlpclf = MLPClassifier(random_state=22, max_iter=750, activation=option)\n",
    "    mlpclf.fit(X_train, y_train)\n",
    "    mlp_score = mlpclf.score(X_test, y_test)\n",
    "    print('The model\\'s score is:', mlp_score, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd61f3ee",
   "metadata": {},
   "source": [
    "The activation options are the activation functions for the hidden layer(s) of the neural network. In this case, the activation option appears to have no bearing on the model's score as all four options yield a score of 1 when the train-test split is 90%-10%. This could likely be due to overfitting to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40dfdf6",
   "metadata": {},
   "source": [
    "### Max Iteration Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "id": "02d8a501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max iterations: 50\n",
      "The model's score is: 0.6 \n",
      "\n",
      "Max iterations: 100\n",
      "The model's score is: 0.9333333333333333 \n",
      "\n",
      "Max iterations: 150\n",
      "The model's score is: 1.0 \n",
      "\n",
      "Max iterations: 200\n",
      "The model's score is: 1.0 \n",
      "\n",
      "Max iterations: 250\n",
      "The model's score is: 1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning) # suppress convergence warnings\n",
    "\n",
    "for i in range(50, 300, 50):\n",
    "    print('Max iterations:', i)\n",
    "    mlpclf = MLPClassifier(random_state=22, max_iter=i)\n",
    "    mlpclf.fit(X_train, y_train)\n",
    "    mlp_score = mlpclf.score(X_test, y_test)\n",
    "    print('The model\\'s score is:', mlp_score, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4202bcd3",
   "metadata": {},
   "source": [
    "The max iterations option determines the maximum number of iterations to cap the model at if convergence is not reached. In this case, convergence is not reached until ~600 maximum iterations. The warnings were suppressed to avoid cluttering the results. We see that with lower iterations, the model's performance is worse. This makes sense since there are fewer iterations for the model to learn, but we still see the issue of the score reaching 1 long before the model converges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bac50a",
   "metadata": {},
   "source": [
    "### Overall Option Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed693643",
   "metadata": {},
   "source": [
    "As we will see later on, it appears the model is overfitting to the data since the score is 1 in most cases. While they have perfect performance, there may still be issues in classifying an iris which is not similar to the data that appears in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5356cf",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb20b4c7",
   "metadata": {},
   "source": [
    "## Training the KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "id": "a828ff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knnclf = KNeighborsClassifier()\n",
    "knnclf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = knnclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240ed8a2",
   "metadata": {},
   "source": [
    "## Predicting Probabilities for Each Class for Sample Data Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "id": "42dd65dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point X0\n",
      "Probability of class 0: 0.0\n",
      "Probability of class 1: 0.0\n",
      "Probability of class 2: 1.0\n",
      "\n",
      "Point X1\n",
      "Probability of class 0: 1.0\n",
      "Probability of class 1: 0.0\n",
      "Probability of class 2: 0.0\n",
      "\n",
      "Point X2\n",
      "Probability of class 0: 0.0\n",
      "Probability of class 1: 1.0\n",
      "Probability of class 2: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the new point X0 and predict the probabilities for each classification\n",
    "y0_pred_knn = knnclf.predict(X0_pred)\n",
    "y0_probs_knn = knnclf.predict_proba(X0_pred)\n",
    "\n",
    "for i in range(len(y0_probs_knn)):\n",
    "    print('Point X' + str(i))\n",
    "    for j in range(len(y0_probs_knn[i])):\n",
    "        print('Probability of class', str(j) + ':', y0_probs_knn[i][j])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "id": "dc833918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a new point X0 the model classifies it as iris 2\n",
      "Given a new point X1 the model classifies it as iris 0\n",
      "Given a new point X2 the model classifies it as iris 1\n"
     ]
    }
   ],
   "source": [
    "# Verify that the model chooses the class with the highest probability\n",
    "for i in range(len(y0_pred_mlp)):\n",
    "    print('Given a new point X' + str(i), 'the model classifies it as iris', y0_pred_knn[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d3cbdc",
   "metadata": {},
   "source": [
    "## Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "id": "9e6f68dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's score is: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Display the model's score\n",
    "knn_score = knnclf.score(X_test, y_test)\n",
    "# knn_score = mlpclf.score(X0_pred, y0_pred_knn)\n",
    "print('The model\\'s score is:', knn_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31897e8",
   "metadata": {},
   "source": [
    "The KNN classifier model has a score of 1, and this means that it can classify a flower as one of the three iris species with about 100% accuracy from the testing set or an entirely new point $X_0$.\n",
    "\n",
    "When using a training set size of 67% and a test set size of 33%, this model has a score of 0.96, meaning it can properly classify the iris species with about 96% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826a4916",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfd80ee",
   "metadata": {},
   "source": [
    "For the three sample data points, I deliberately chose $x_0, x_1,$ and $x_2$ to be double the max of each feature, half the min of each feature, and the 50th percentile of each feature to gain some intuition into how these features relate to the three classes. The results show that as the sepal length, sepal width, petal length, and petal width increase, the classification also \"increases.\" In this context, \"increases\" refers to how the classifications, or iris species, appear to correspond to how large these 4 features are. This means that class 0 seems to correspond to smaller irises, class 1 seems to correspond to medium-sized irises, and class 2 seems to correspond to larger irises.\n",
    "\n",
    "All of the models except for the SVM had scores of 1 while the SVM had a score of 0.93 when using a train set size of 90% and a test set size of 10%. This suggests that the models may have been overfit to the training data. By changing the train set and test set sizes to 67% and 33% respectively, the models had the following scores:\n",
    "* Logistic regression -> 0.96\n",
    "* Support vector machine -> 0.92\n",
    "* Neural network -> 1\n",
    "* K-nearest neighbors -> 0.96\n",
    "\n",
    "While the scores are still quite high, these results seem to be better as it is unrealistic for most models to have a score of 1. This change can be seen as the models not overfitting to the training data as much. When the training set size is 90%, there are only 15 samples in the test set. This makes the probability of the models learning points similar to those in the testing set higher than if the training set size is 67%. The models will have a greater chance of properly classifying all of the test points as opposed to when the train set is smaller and the test set is larger as a result. However, even with this change, the models still come close to scores of 1. This reveals that many of the data points may be very similar to each other, allowing for the models to still accurately predict the class for a given iris.\n",
    "\n",
    "Among the four models analyzed in this exercise, I believe the logistic regression model performed the best. Even though it did not have the highest score after modifying the training and testing split, analyzing the probabilities for the three sample data points $X_0, X_1,$ and $X_2$ shows that the logistic regression model had the highest probabilities for the \"correct\" classes for the original training and testing split, barring the KNN model. I believe this is better than the perfect probabilities of the KNN model for the same reasons as the scores; the logistic regression model had predictions close to 1, but also was more uncertain about $X_1$. This uncertainty shows that it is likely not as tightly fit to the original data as the KNN model. This is further supported by the scores coming from the modified training and testing split.\n",
    "\n",
    "Seeing the perfect scores initially surprised me since it is unusual to come across models with scores that high, even while tweaking parameters and the data. After taking some time to think about how this could have happened, this result is less surprising."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
